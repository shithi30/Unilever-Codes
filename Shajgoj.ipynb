{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a70264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped from page: 0, SKUs found: 21\n",
      "Data scraped from page: 1, SKUs found: 21\n",
      "Data scraped from page: 2, SKUs found: 21\n",
      "Data scraped from page: 3, SKUs found: 21\n",
      "Data scraped from page: 4, SKUs found: 21\n",
      "Data scraped from page: 5, SKUs found: 21\n",
      "Data scraped from page: 6, SKUs found: 21\n",
      "Data scraped from page: 7, SKUs found: 8\n",
      "\n",
      "Total SKUs found: 155\n",
      "Elapsed time to scrape (mins): 7.91\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import duckdb\n",
    "import win32com.client\n",
    "from pretty_html_table import build_table\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# accumulators\n",
    "start_time = time.time()\n",
    "df_acc = pd.DataFrame()\n",
    "pg = 0\n",
    "\n",
    "while (1):\n",
    "    # page\n",
    "    driver = webdriver.Chrome('chromedriver', options=[])\n",
    "    url = 'https://shop.shajgoj.com/shop/#q=unilever&hPP=21&idx=wp_posts_product&p=' + str(pg) + '&is_v=1'\n",
    "    driver.get(url)\n",
    "\n",
    "    # scroll\n",
    "    SCROLL_PAUSE_TIME = 5\n",
    "    # get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        # till bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        # calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height: break\n",
    "        last_height = new_height\n",
    "\n",
    "    # soup\n",
    "    soup_init = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    soup = soup_init.find_all(\"div\", attrs={\"class\": \"ais-infinite-hits--item ais-hits--item\"})\n",
    "    driver.close()\n",
    "\n",
    "    # title\n",
    "    title = [s.find(\"a\", attrs={\"class\": \"product_title\"}).get_text() for s in soup]\n",
    "\n",
    "    # quantity\n",
    "    qty = [s.find(\"div\", attrs={\"class\": \"alg-variation\"}).get_text().replace('\\n', \"\") for s in soup]\n",
    "    qty_val = []\n",
    "    qty_unit = []\n",
    "    r = re.compile(\"([0-9]+)([a-zA-Z]+)\")\n",
    "    for q in qty:\n",
    "        if q != '':\n",
    "            qty_val.append(float(r.match(q).group(1)))\n",
    "            qty_unit.append(r.match(q).group(2).lower())\n",
    "        else:\n",
    "            qty_val.append(None)\n",
    "            qty_unit.append(\"\")\n",
    "\n",
    "    # price\n",
    "    price = [s.find(\"p\", attrs={\"class\": \"alg-hit__priceholder product_price_placeholder\"}).get_text() for s in soup]\n",
    "    original_price = []\n",
    "    discounted_price = []\n",
    "    for p in price:\n",
    "        sp = p.split('鄑許\xa0')\n",
    "        original_price.append(float(sp[1].replace('\\n', \"\").replace('\\t', \"\").replace('鄑許\xa0', \"\").replace(',', \"\")))\n",
    "        if len(sp) > 2:\n",
    "            discounted_price.append(\n",
    "                float(sp[2].replace('\\n', \"\").replace('\\t', \"\").replace('鄑許\xa0', \"\").replace(',', \"\")))\n",
    "        else:\n",
    "            discounted_price.append(\n",
    "                float(sp[1].replace('\\n', \"\").replace('\\t', \"\").replace('鄑許\xa0', \"\").replace(',', \"\")))\n",
    "\n",
    "    # rating\n",
    "    rating = [s.find(\"span\", attrs={\"class\": \"alg-rating\"})['style'] for s in soup]\n",
    "    rating = [float(re.findall(r'\\d+', r)[0]) / 20 for r in rating]\n",
    "\n",
    "    # option\n",
    "    opt = [s.find(\"div\", attrs={\"class\": \"alg-hit__actions\"}).get_text() for s in soup]\n",
    "    opt = [o.replace('\\n', \"\").replace('\\t', \"\") for o in opt]\n",
    "\n",
    "    # offer\n",
    "    offer = [s.find(\"div\", attrs={\"class\": \"alg-product-ribbon-container\"}).get_text() for s in soup]\n",
    "    offer = [o.replace('\\n', \"\").replace('\\t', \"\").replace('\\xa0', \"\") for o in offer]\n",
    "\n",
    "    # scraped data\n",
    "    df = pd.DataFrame()\n",
    "    df['title'] = title\n",
    "    df['brand_derived'] = [t.split()[0].replace(\"'\", \"\") for t in title]\n",
    "    df['quantity_value'] = qty_val\n",
    "    df['quantity_unit'] = qty_unit\n",
    "    df['original_price'] = original_price\n",
    "    df['discounted_price'] = discounted_price\n",
    "    df['offer'] = offer\n",
    "    df['rating'] = rating\n",
    "    df['option'] = opt\n",
    "    df['source_page'] = pg\n",
    "    df_acc = df_acc.append(df)\n",
    "\n",
    "    # loop control\n",
    "    if df.shape[0] == 0: break\n",
    "    print(\"Data scraped from page: \" + str(pg) + \", SKUs found: \" + str(df.shape[0]))\n",
    "    pg = pg + 1\n",
    "\n",
    "# stats\n",
    "print()\n",
    "print(\"Total SKUs found: \" + str(df_acc.shape[0]))\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time to scrape (mins): \" + str(round(elapsed_time / 60.00, 2)))\n",
    "df_acc = df_acc.reset_index(drop=True)\n",
    "\n",
    "# csv\n",
    "qry = '''\n",
    "select \n",
    "    title,\n",
    "    brand_derived, \n",
    "    quantity_value, \n",
    "    quantity_unit, \n",
    "    original_price, \n",
    "    case when (discounted_price<original_price) then discounted_price else null end discounted_price, \n",
    "    case when (discounted_price<original_price) then (original_price-discounted_price)/original_price else null end discount_pct,\n",
    "    case when offer like '%SOLD OUT%' then '' else offer end offer, \n",
    "    case when rating=0 then null else rating end rating, \n",
    "    option, \n",
    "    source_page\n",
    "from df_acc; \n",
    "'''\n",
    "df_acc_csv = duckdb.query(qry).df()\n",
    "df_acc_csv.to_csv(\"shajgoj_unilever_skus_data.csv\", index=False)\n",
    "\n",
    "# analyse\n",
    "qry = '''\n",
    "select \n",
    "    brand_derived brand, \n",
    "    count(*) \"SKUs enlisted\", \n",
    "    count(case when option='REQUEST STOCK' then title else null end) \"SKUs out of stock\", \n",
    "    count(case when option='REQUEST STOCK' then title else null end)*1.00/count(*) \"SKUs out of stock pct\", \n",
    "    count(case when offer!='' then title else null end) \"SKUs giving offer\", \n",
    "    count(case when discounted_price is not null then title else null end) \"SKUs giving discount\",\n",
    "    avg(discount_pct) \"avg. discount pct\",\n",
    "    avg(rating) \"avg. rating\"\n",
    "from \n",
    "    df_acc_csv tbl1 \n",
    "\n",
    "    inner join \n",
    "\n",
    "    (-- top-05 SKUs\n",
    "    select brand_derived, count(*) skus\n",
    "    from df_acc_csv\n",
    "    group by 1 \n",
    "    order by 2 desc\n",
    "    limit 7\n",
    "    ) tbl2 using(brand_derived)\n",
    "group by 1\n",
    "order by 2 desc; \n",
    "'''\n",
    "res_df = duckdb.query(qry).df()\n",
    "\n",
    "# # email\n",
    "# ol = win32com.client.Dispatch(\"outlook.application\")\n",
    "# olmailitem = 0x0\n",
    "# newmail = ol.CreateItem(olmailitem)\n",
    "#\n",
    "# # subject, recipients\n",
    "# newmail.Subject = 'Scraped & Analysed: shajgoj.com'\n",
    "# newmail.To = 'avra.barua@unilever.com'\n",
    "# newmail.CC = 'mehedi.asif@unilever.com'\n",
    "#\n",
    "# # body\n",
    "# newmail.HTMLbody = f'''\n",
    "# Hello Bhaiya,<br><br>\n",
    "# Please find below an analysis of popular Unilever SKUs available on shajgoj.com.<br>\n",
    "# ''' + build_table(res_df, 'blue_light') + '''\n",
    "# Also, the complete search results are available in the attachment for your convenience.<br><br>\n",
    "# Note that, the data was extracted at ''' + time.strftime('%d-%b-%y, %I:%M %p') + '''. This is an auto generated email using smtplib.<br><br>\n",
    "# Thanks,<br>\n",
    "# Shithi Maitra<br>\n",
    "# Asst. Manager, Cust. Service Excellence<br>\n",
    "# Unilever BD Ltd.<br>\n",
    "# '''\n",
    "#\n",
    "# # attachment(s)\n",
    "# attachment = ['shajgoj_unilever_skus_data.csv']\n",
    "# for atch in attachment:\n",
    "#     newmail.Attachments.Add(os.getcwd() + '\\\\' + atch)\n",
    "#\n",
    "# # display, send\n",
    "# # newmail.Display()\n",
    "# newmail.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1cff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
