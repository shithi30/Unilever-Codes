{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd61a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.formatting.rule import Rule\n",
    "from openpyxl.styles.differential import DifferentialStyle\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "import win32com.client\n",
    "from win32com.client import Dispatch\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26daccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read target/Stock Alloc\n",
    "def read_tgt_file():\n",
    "    file = \"C:/Users/Shithi.Maitra/Unilever Codes/Ad Hoc/2by2 Matrices/RPL Inputs/\" + \"February'24 Town x SKU Stock Allocation_National.xlsx\"\n",
    "    sheet_name = \"Town x SKU x Case x TGT \"\n",
    "    df = pd.read_excel(open(file, \"rb\"), sheet_name=sheet_name, header=2, index_col=None)\n",
    "    tgt_df = df[['CATEGORY', 'TOWN NAME', 'SKU NAME', 'TOWN x SKU TGT - TP Cr.']]\n",
    "    tgt_df.columns = ['category', 'town', 'basepack', 'tgt_cr']\n",
    "    tgt_df = duckdb.query('''select upper(category) category, upper(town) town, upper(basepack) basepack, tgt_cr from tgt_df''').df()\n",
    "    return tgt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba5bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read RPL\n",
    "def fetch_read_rpl(rec_date_from, rec_date_to): \n",
    "    \n",
    "    # inputs\n",
    "    subject_pattern = 'Replenishment Report'\n",
    "    atch_pattern = 'Replenishment Repot'\n",
    "\n",
    "    # output folder\n",
    "    output_dir = Path.cwd() / 'RPL Inputs'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # output files\n",
    "    filenames = []\n",
    "\n",
    "    # outlook inbox\n",
    "    outlook = win32com.client.Dispatch('Outlook.Application').GetNamespace('MAPI')\n",
    "    inbox = outlook.Folders.Item(1).Folders['Kader Bhai']\n",
    "\n",
    "    # emails\n",
    "    messages = inbox.Items\n",
    "    for message in reversed(messages): \n",
    "\n",
    "        # time\n",
    "        try: rec_date = str(message.SentOn)[0:10]\n",
    "        except: continue\n",
    "        if rec_date < rec_date_from or rec_date > rec_date_to: continue\n",
    "\n",
    "        # subject\n",
    "        subject = message.Subject\n",
    "        if subject_pattern.lower() not in subject.lower(): continue\n",
    "\n",
    "        # attachments\n",
    "        attachments = message.Attachments\n",
    "        for attachment in attachments:\n",
    "            filename = rec_date + '_' + attachment.FileName\n",
    "            if atch_pattern.lower() in filename.lower(): \n",
    "                filenames.append(filename)\n",
    "                attachment.SaveAsFile(output_dir / filename)\n",
    "\n",
    "    # read\n",
    "    rpl_df = pd.DataFrame()\n",
    "    for f in filenames:\n",
    "        print(\"Reading: \" + f)\n",
    "        file = \"C:/Users/Shithi.Maitra/Unilever Codes/Ad Hoc/2by2 Matrices/RPL Inputs/\" + f\n",
    "        df = pd.read_excel(open(file, \"rb\"), sheet_name=\"Replenishment UBL_UCL\", header=0, index_col=None)\n",
    "        df = df[['Date', 'Town', 'Basepack', 'Proposed qty', 'Norm qty']]\n",
    "        df.columns = ['rpl_date', 'town', 'basepack', 'proposed_qty', 'norm_qty']\n",
    "        df = duckdb.query('''select strptime(rpl_date, '%d %b %Y') rpl_date, upper(town) town, upper(basepack) basepack, proposed_qty, norm_qty from df''').df()\n",
    "        rpl_df = rpl_df.append(df)\n",
    "    return rpl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb65200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare report\n",
    "def prepare_report(rec_date_from, rec_date_to, rpl_df, sheet_name):\n",
    "    \n",
    "    # prepare RPL\n",
    "    rpl_df = rpl_df.fillna(-0.01)\n",
    "    qry = '''\n",
    "    select \n",
    "        case when basepack is not null then basepack else 'unspecified' end basepack, \n",
    "        case when category is not null then category else 'unspecified' end category, \n",
    "        case when town is not null then town else 'unspecified' end town, \n",
    "        proposed_qty, norm_qty, qmix, \n",
    "        case when bp_tgt_cr*1.00/tot_tgt_cr is null then 0 else bp_tgt_cr*1.00/tot_tgt_cr end bp_bc, \n",
    "        case when town_tgt_cr*1.00/tot_tgt_cr is null then 0 else town_tgt_cr*1.00/tot_tgt_cr end town_bc\n",
    "    from \n",
    "        (select basepack, town, sum(proposed_qty) proposed_qty, sum(norm_qty) norm_qty, 1-sum(proposed_qty)*1.00/sum(norm_qty) qmix\n",
    "        from rpl_df\n",
    "        group by 1, 2\n",
    "        ) tbl0\n",
    "\n",
    "        full join\n",
    "\n",
    "        (select basepack, sum(tgt_cr) bp_tgt_cr\n",
    "        from tgt_df\n",
    "        group by 1\n",
    "        ) tbl2 using(basepack)\n",
    "\n",
    "        full join\n",
    "\n",
    "        (select town, sum(tgt_cr) town_tgt_cr\n",
    "        from tgt_df\n",
    "        group by 1\n",
    "        ) tbl3 using(town)\n",
    "\n",
    "        left join \n",
    "\n",
    "        (select distinct basepack, category\n",
    "        from tgt_df\n",
    "        ) tbl4 using(basepack), \n",
    "\n",
    "        (select sum(tgt_cr) tot_tgt_cr\n",
    "        from tgt_df\n",
    "        ) tbl5\n",
    "    order by bp_bc desc\n",
    "    '''\n",
    "    rpl_df_contrib = duckdb.query(qry).df()\n",
    "\n",
    "    # order columns\n",
    "    qry = '''\n",
    "    select \n",
    "        town, \n",
    "        max(town_bc) town_bc, \n",
    "        sum(max(town_bc)) over(order by max(town_bc) desc) town_bc_cum,\n",
    "        1-sum(proposed_qty)*1.00/sum(norm_qty) town_qmix\n",
    "    from rpl_df_contrib\n",
    "    group by 1\n",
    "    order by town_bc desc\n",
    "    '''\n",
    "    ord_df = duckdb.query(qry).df()\n",
    "    town_ord = ord_df['town'].tolist()\n",
    "\n",
    "    # town BC\n",
    "    town_bc_cum_ord = ['town_bc_cum'] + ord_df['town_bc_cum'].tolist()\n",
    "    town_bc_cum_ord = pd.DataFrame([town_bc_cum_ord])\n",
    "    town_bc_ord = ['town_bc'] + ord_df['town_bc'].tolist()\n",
    "    town_bc_ord = pd.DataFrame([town_bc_ord])\n",
    "    town_qmix_ord = ['town_qmix'] + ord_df['town_qmix'].tolist()\n",
    "    town_qmix_ord = pd.DataFrame([town_qmix_ord])\n",
    "\n",
    "    # basepack BC\n",
    "    qry = '''\n",
    "    select \n",
    "        category, \n",
    "        basepack, \n",
    "        max(bp_bc) basepack_bc, \n",
    "        sum(max(bp_bc)) over(order by max(bp_bc) desc) basepack_bc_cum,\n",
    "        1-sum(proposed_qty)*1.00/sum(norm_qty) basepack_qmix\n",
    "    from rpl_df_contrib\n",
    "    group by 1, 2\n",
    "    order by basepack_bc desc\n",
    "    '''\n",
    "    bp_bc_df = duckdb.query(qry).df()[['basepack_bc_cum', 'basepack_bc', 'basepack_qmix', 'category']]\n",
    "    \n",
    "    # national\n",
    "    qry = '''\n",
    "    select * \n",
    "    from \n",
    "        (select 1-sum(proposed_qty)*1.00/sum(norm_qty) national_qmix\n",
    "        from rpl_df_contrib\n",
    "        ) tbl1, \n",
    "        (select 1-sum(proposed_qty)*1.00/sum(norm_qty) national_qmix_excluding_mtsmtwt\n",
    "        from rpl_df_contrib\n",
    "        where town not in('WATER-DHAKA', 'MODERN TRADE', 'SMT & SHOPPING COMPL', 'OOH DISTRIBUTOR DHAK')\n",
    "        ) tbl2\n",
    "    '''\n",
    "    national_df = duckdb.query(qry).df()\n",
    "\n",
    "    # pivot\n",
    "    rpl_df_piv = pd.pivot_table(rpl_df_contrib.fillna(-0.01), values='qmix', index=['basepack'], columns='town', sort=False).fillna(-0.01)\n",
    "    rpl_df_piv = rpl_df_piv[town_ord]\n",
    "    \n",
    "    # path\n",
    "    path = 'C:/Users/Shithi.Maitra/OneDrive - Unilever/2d Matrices/QMix Matrices/QMix_2by2_Matrix_' + rec_date_from[0:7] + '.xlsx'\n",
    "\n",
    "    # if exists\n",
    "    if_exists = 1\n",
    "    try: book = load_workbook(path)\n",
    "    except: if_exists = 0\n",
    "\n",
    "    # writer\n",
    "    writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "\n",
    "    # create/retrieve/remove sheet(s)\n",
    "    if if_exists == 1: \n",
    "        writer.book = book\n",
    "        if sheet_name in book.sheetnames:\n",
    "            if rec_date_from != rec_date_to:\n",
    "                try: del writer.book[sheet_name] # sheet exists \n",
    "                except: pass                     # sheet does not exist\n",
    "            else: \n",
    "                writer.close()\n",
    "                return\n",
    "         \n",
    "    # write\n",
    "    national_df.to_excel(writer, sheet_name=sheet_name, startrow=0, startcol=3, index=False)\n",
    "    town_bc_cum_ord.to_excel(writer, sheet_name=sheet_name, startrow=2, startcol=4, header=False, index=False)\n",
    "    town_bc_ord.to_excel(writer, sheet_name=sheet_name, startrow=3, startcol=4, header=False, index=False)\n",
    "    town_qmix_ord.to_excel(writer, sheet_name=sheet_name, startrow=4, startcol=4, header=False, index=False)\n",
    "    rpl_df_piv.to_excel(writer, sheet_name=sheet_name, startrow=5, startcol=4)\n",
    "    bp_bc_df.to_excel(writer, sheet_name=sheet_name, startrow=5, startcol=0, index=False)\n",
    "\n",
    "    # adjust\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    for column_cells in worksheet.columns:\n",
    "        length = max(len(\"\".join(c for c in str(cell.value).replace(' ', 'A') if c.isalpha())) for cell in column_cells)        \n",
    "        worksheet.column_dimensions[openpyxl.utils.get_column_letter(column_cells[0].column)].width = length + 4\n",
    "    writer.close()\n",
    "    \n",
    "    # format\n",
    "    workbook = load_workbook(path)\n",
    "    worksheet = workbook[sheet_name]\n",
    "    \n",
    "    # percent\n",
    "    column_letters = [col.column_letter for col in worksheet[1]]\n",
    "    for col in column_letters: \n",
    "        for cel in worksheet[(col)]: \n",
    "            cel.number_format = \"0.00%\"\n",
    "    \n",
    "    # color\n",
    "    font = Font(bold = True, color = 'EE1111')\n",
    "    dxf = DifferentialStyle(font = font)\n",
    "    rule = Rule(type = 'cellIs', operator = 'between', formula = [0.001, national_df['national_qmix'].tolist()[0]], dxf = dxf)\n",
    "    worksheet.conditional_formatting.add('C5:GZ300', rule)\n",
    "    \n",
    "    # freeze\n",
    "    worksheet.freeze_panes = worksheet['F7']\n",
    "    \n",
    "    # save\n",
    "    workbook.save(path)\n",
    "\n",
    "    # tabs in sheet\n",
    "    print(\"Worksheets in workbook: \")\n",
    "    print(pd.ExcelFile(path).sheet_names)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487d3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e06f96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-16', '2024-02-17', '2024-02-18']\n"
     ]
    }
   ],
   "source": [
    "# month, dates, target\n",
    "tgt_df = read_tgt_file()\n",
    "\n",
    "current_month = datetime.today().strftime('%Y-%m-%d')[0:7]\n",
    "qry = '''\n",
    "select (concat(left(current_date, 7), '-01')::date + generate_series::int)::text qmix_date\n",
    "from (select * from generate_series(0, 100)) tbl1 \n",
    "where generate_series < date_part('day', current_date)\n",
    "'''\n",
    "qmix_dates = duckdb.query(qry).df()['qmix_date'].tolist()\n",
    "\n",
    "# current_month = '2024-01'\n",
    "# qmix_dates = ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05', '2024-01-06', '2024-01-07', '2024-01-08', '2024-01-09', '2024-01-10', '2024-01-11', '2024-01-12', '2024-01-13', '2024-01-14', '2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18', '2024-01-19', '2024-01-20', '2024-01-21', '2024-01-22', '2024-01-23', '2024-01-24', '2024-01-25', '2024-01-26', '2024-01-27', '2024-01-28', '2024-01-29', '2024-01-30', '2024-01-31']\n",
    "\n",
    "print(qmix_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833290f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 2024-02-18_Replenishment Repot_18 Feb 2024.xlsx\n",
      "Reading: 2024-02-17_Replenishment Repot_17 Feb 2024.xlsx\n",
      "Reading: 2024-02-15_Replenishment Repot_15 Feb 2024.xlsx\n",
      "Reading: 2024-02-14_Replenishment Repot_14 Feb 2024.xlsx\n",
      "Reading: 2024-02-13_Replenishment Repot_13 Feb 2024.xlsx\n",
      "Reading: 2024-02-12_Replenishment Repot_12 Feb 2024.xlsx\n",
      "Reading: 2024-02-11_Replenishment Repot_11 Feb 2024.xlsx\n",
      "Reading: 2024-02-10_Replenishment Repot_10 Feb 2024.xlsx\n",
      "Reading: 2024-02-08_Replenishment Repot_08 Feb 2024.xlsx\n",
      "Reading: 2024-02-07_Replenishment Repot_07 Feb 2024.xlsx\n",
      "Reading: 2024-02-06_Replenishment Repot_06 Feb 2024.xlsx\n",
      "Reading: 2024-02-05_Replenishment Repot_05 Feb 2024.xlsx\n",
      "Reading: 2024-02-04_Replenishment Repot_04 Feb 2024.xlsx\n",
      "Reading: 2024-02-03_Replenishment Repot_03 Feb 2024.xlsx\n",
      "Reading: 2024-02-01_Replenishment Repot_01 Feb 2024.xlsx\n"
     ]
    }
   ],
   "source": [
    "# RPL\n",
    "rec_date_from = qmix_dates[0]\n",
    "rec_date_to = qmix_dates[len(qmix_dates)-1]\n",
    "rpl_df = fetch_read_rpl(rec_date_from, rec_date_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2383640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RPL\n",
    "# rec_date_from = qmix_dates[0]\n",
    "# rec_date_to = qmix_dates[len(qmix_dates)-1]\n",
    "# filenames = [\n",
    "#     'Replenishment Repot_01 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_02 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_03 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_04 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_05 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_06 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_07 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_08 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_08 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_10 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_11 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_12 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_13 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_14 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_15 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_16 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_17 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_18 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_19 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_20 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_21 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_22 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_23 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_24 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_25 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_26 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_27 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_28 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_29 Jan 2024.xlsx',\n",
    "#     'Replenishment Repot_30 Jan 2024.xlsx',\n",
    "    \n",
    "#     'Replenishment Repot_31 Jan 2024.xlsx'\n",
    "# ]\n",
    "# rpl_df = pd.DataFrame()\n",
    "# for f in filenames:\n",
    "#     file = \"C:/Users/Shithi.Maitra/Unilever Codes/Ad Hoc/2by2 Matrices/RPL Inputs/\" + f\n",
    "#     print(1)\n",
    "#     try: df = pd.read_excel(open(file, \"rb\"), sheet_name=\"Replenishment UBL_UCL\", header=0, index_col=None)\n",
    "#     except: continue\n",
    "#     print(\"Reading: \" + f)\n",
    "#     df = df[['Date', 'Town', 'Basepack', 'Proposed qty', 'Norm qty']]\n",
    "#     df.columns = ['rpl_date', 'town', 'basepack', 'proposed_qty', 'norm_qty']\n",
    "#     df = duckdb.query('''select strptime(rpl_date, '%d %b %Y') rpl_date, upper(town) town, upper(basepack) basepack, proposed_qty, norm_qty from df''').df()\n",
    "#     rpl_df = rpl_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89576262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-MTD', '2024-02-TDP1', '2024-02-TDP2', '2024-02-trends', '2024-02-17']\n",
      "\n",
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-MTD', '2024-02-TDP1', '2024-02-TDP2', '2024-02-trends', '2024-02-17', '2024-02-18']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# daily\n",
    "for qmix_date in qmix_dates:\n",
    "    day_df = duckdb.query(\"select * from rpl_df where rpl_date='\" + qmix_date + \"'\").df()\n",
    "    if day_df.shape[0] == 0: continue\n",
    "    prepare_report(qmix_date, qmix_date, day_df, qmix_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a970d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-TDP1', '2024-02-TDP2', '2024-02-trends', '2024-02-17', '2024-02-18', '2024-02-MTD']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MTD\n",
    "prepare_report(rec_date_from, rec_date_to, rpl_df, current_month + \"-MTD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9872f58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-TDP2', '2024-02-trends', '2024-02-17', '2024-02-18', '2024-02-MTD', '2024-02-TDP1']\n",
      "\n",
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-trends', '2024-02-17', '2024-02-18', '2024-02-MTD', '2024-02-TDP1', '2024-02-TDP2']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TDP-01\n",
    "rec_date_from = current_month + \"-01\"\n",
    "rec_date_to = current_month + \"-10\"\n",
    "tdp_df = duckdb.query(\"select * from rpl_df where rpl_date>='\" + rec_date_from + \"' and rpl_date<='\" + rec_date_to + \"'\").df()\n",
    "prepare_report(rec_date_from, rec_date_to, tdp_df, current_month + \"-TDP1\")\n",
    "\n",
    "# TDP-02\n",
    "rec_date_from = current_month + \"-11\"\n",
    "rec_date_to = current_month + \"-20\"\n",
    "tdp_df = duckdb.query(\"select * from rpl_df where rpl_date>='\" + rec_date_from + \"' and rpl_date<='\" + rec_date_to + \"'\").df()\n",
    "prepare_report(rec_date_from, rec_date_to, tdp_df, current_month + \"-TDP2\")\n",
    "\n",
    "# # TDP-03\n",
    "# rec_date_from = current_month + \"-21\"\n",
    "# rec_date_to = qmix_dates[len(qmix_dates)-1]\n",
    "# tdp_df = duckdb.query(\"select * from rpl_df where rpl_date>='\" + rec_date_from + \"' and rpl_date<='\" + rec_date_to + \"'\").df()\n",
    "# prepare_report(rec_date_from, rec_date_to, tdp_df, current_month + \"-TDP3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060288bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-17', '2024-02-18', '2024-02-MTD', '2024-02-TDP1', '2024-02-TDP2', '2024-02-trends']\n"
     ]
    }
   ],
   "source": [
    "## trend ##\n",
    "\n",
    "# path\n",
    "path = 'C:/Users/Shithi.Maitra/OneDrive - Unilever/2d Matrices/QMix Matrices/QMix_2by2_Matrix_' + current_month + '.xlsx'\n",
    "\n",
    "# sheets\n",
    "sheets = pd.ExcelFile(path).sheet_names\n",
    "\n",
    "# trend data\n",
    "qry = '''\n",
    "select left(rpl_date::text, 10) qmix_date, basepack, town, 1-sum(proposed_qty)*1.00/sum(norm_qty) qmix\n",
    "from rpl_df\n",
    "group by 1, 2, 3\n",
    "union all \n",
    "select left(rpl_date::text, 10) qmix_date, 'overall' basepack, town, 1-sum(proposed_qty)*1.00/sum(norm_qty) qmix\n",
    "from rpl_df\n",
    "group by 1, 2, 3\n",
    "union all \n",
    "select left(rpl_date::text, 10) qmix_date, basepack, 'overall' town, 1-sum(proposed_qty)*1.00/sum(norm_qty) qmix\n",
    "from rpl_df\n",
    "group by 1, 2, 3\n",
    "'''\n",
    "trend_df = duckdb.query(qry).df()\n",
    "trend_df_piv = pd.pivot_table(trend_df.fillna(-0.01), values='qmix', index=['town', 'basepack'], columns='qmix_date', sort=False).fillna(-0.01)\n",
    "\n",
    "# benchmark\n",
    "qry = '''\n",
    "select 1-sum(proposed_qty)*1.00/sum(norm_qty) benchmark_qmix\n",
    "from rpl_df\n",
    "'''\n",
    "benchmark = duckdb.query(qry).df()['benchmark_qmix'].tolist()[0] \n",
    "\n",
    "# load\n",
    "book = load_workbook(path)\n",
    "\n",
    "# writer\n",
    "writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "\n",
    "# create, retrieve, remove sheets\n",
    "sheet_name = current_month + '-trends'\n",
    "writer.book = book\n",
    "if sheet_name in sheets: del writer.book[sheet_name]\n",
    "\n",
    "# write\n",
    "trend_df_piv.reset_index().to_excel(writer, sheet_name=sheet_name, startrow=0, startcol=0, index = False)\n",
    "\n",
    "# adjust\n",
    "worksheet = writer.sheets[sheet_name]\n",
    "it = 1\n",
    "for column_cells in worksheet.columns:\n",
    "    if it in [1, 2]: length = max(len(\"\".join(c for c in str(cell.value).replace(' ', 'A') if c.isalpha())) for cell in column_cells)  \n",
    "    else: length = len(str(column_cells[0].value))\n",
    "    worksheet.column_dimensions[openpyxl.utils.get_column_letter(column_cells[0].column)].width = length + 4\n",
    "    it = it + 1\n",
    "writer.close()\n",
    "\n",
    "# format\n",
    "workbook = load_workbook(path)\n",
    "worksheet = workbook[sheet_name]\n",
    "\n",
    "# freeze\n",
    "worksheet.freeze_panes = worksheet['C2']\n",
    "\n",
    "# filter\n",
    "worksheet.auto_filter.ref = worksheet.dimensions\n",
    "\n",
    "# percent\n",
    "column_letters = [col.column_letter for col in worksheet[1]]\n",
    "for col in column_letters: \n",
    "    for cel in worksheet[(col)]: \n",
    "        cel.number_format = \"0.00%\" \n",
    "        \n",
    "# color\n",
    "font = Font(bold = True, color = 'EE1111')\n",
    "dxf = DifferentialStyle(font = font)\n",
    "rule = Rule(type = 'cellIs', operator = 'between', formula = [0.001, benchmark], dxf = dxf)\n",
    "worksheet.conditional_formatting.add('C5:AH50000', rule)\n",
    "    \n",
    "# save\n",
    "workbook.save(path)\n",
    "\n",
    "# tabs in sheet\n",
    "print(\"Worksheets in workbook: \")\n",
    "print(pd.ExcelFile(path).sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656b18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to run script (mins): 43.72\n"
     ]
    }
   ],
   "source": [
    "# report\n",
    "elapsed_time = str(round((time.time() - start_time) / 60.00, 2))\n",
    "print(\"Elapsed time to run script (mins): \" + elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d1be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
