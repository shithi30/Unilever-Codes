{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd61a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.formatting.rule import Rule\n",
    "from openpyxl.styles.differential import DifferentialStyle\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "import win32com.client\n",
    "from win32com.client import Dispatch\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26daccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read target/Stock Alloc\n",
    "def read_tgt_file():\n",
    "    file = \"C:/Users/Shithi.Maitra/Unilever Codes/Ad Hoc/2by2 Matrices/RPL Inputs/\" + \"February'24 Town x SKU Stock Allocation_National.xlsx\"\n",
    "    sheet_name = \"Town x SKU x Case x TGT \"\n",
    "    df = pd.read_excel(open(file, \"rb\"), sheet_name=sheet_name, header=2, index_col=None)\n",
    "    tgt_df = df[['CATEGORY', 'TOWN NAME', 'SKU NAME', 'TOWN x SKU TGT - TP Cr.']]\n",
    "    tgt_df.columns = ['category', 'town', 'basepack', 'tgt_cr']\n",
    "    tgt_df = duckdb.query('''select upper(category) category, upper(town) town, upper(basepack) basepack, tgt_cr from tgt_df''').df()\n",
    "    return tgt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e425daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SCCF\n",
    "def fetch_read_sccf(rec_date_from, rec_date_to): \n",
    "    \n",
    "    # inputs\n",
    "    subject_pattern = 'Secondary CCFOT'\n",
    "\n",
    "    # output folder\n",
    "    output_dir = Path.cwd() / 'SCCF Inputs'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # output files\n",
    "    filenames = set()\n",
    "\n",
    "    # outlook inbox\n",
    "    outlook = win32com.client.Dispatch('Outlook.Application').GetNamespace('MAPI')\n",
    "    inbox = outlook.Folders.Item(1).Folders['Kader Bhai']\n",
    "\n",
    "    # emails\n",
    "    messages = inbox.Items\n",
    "    for message in reversed(messages): \n",
    "\n",
    "        # subject\n",
    "        subject = message.Subject\n",
    "        if subject_pattern.lower() not in subject.lower(): continue\n",
    "\n",
    "        # attachments\n",
    "        attachments = message.Attachments\n",
    "        for attachment in attachments:\n",
    "            filename = attachment.FileName\n",
    "            try: file_date = str(datetime.strptime(\" \".join(filename.split()[3:6])[0:-9], '%d %b %Y'))[0:10]\n",
    "            except: file_date = str(datetime.strptime(\" \".join(filename.split()[3:6])[0:-9], '%d %B %Y'))[0:10]\n",
    "            if file_date >= rec_date_from and file_date <= rec_date_to:\n",
    "                filenames.add(filename)\n",
    "                attachment.SaveAsFile(output_dir / filename)\n",
    "                \n",
    "    # read\n",
    "    sccf_df = pd.DataFrame()\n",
    "    for f in filenames:\n",
    "        print(\"Reading: \" + f)\n",
    "        file = \"C:/Users/Shithi.Maitra/Unilever Codes/Ad Hoc/2by2 Matrices/SCCF Inputs/\" + f\n",
    "        df = pd.read_excel(open(file, \"rb\"), sheet_name=\"Sheet1\", header=1, index_col=None)\n",
    "        df = df[['Local Sales Region 4', 'Pack Size', 'CS', 'CS.1']]\n",
    "        df.columns = ['town', 'basepack', 'ord_qty', 'inv_qty']\n",
    "        df = duckdb.query('''select upper(town) town, upper(basepack) basepack, ord_qty, inv_qty from df''').df()\n",
    "        try: df['sccf_date'] = str(datetime.strptime(\" \".join(f.split()[3:6])[0:-9], '%d %B %Y'))[0:10]\n",
    "        except: df['sccf_date'] = str(datetime.strptime(\" \".join(f.split()[3:6])[0:-9], '%d %b %Y'))[0:10]\n",
    "        sccf_df = sccf_df.append(df)\n",
    "    return sccf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26971ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare report\n",
    "def prepare_report(rec_date_from, rec_date_to, sccf_df, sheet_name):\n",
    "    \n",
    "    # prepare SCCF\n",
    "    sccf_df = sccf_df.fillna(-0.01)\n",
    "    qry = '''\n",
    "    select \n",
    "        case when basepack is not null then basepack else 'unspecified' end basepack, \n",
    "        case when category is not null then category else 'unspecified' end category, \n",
    "        case when town is not null then town else 'unspecified' end town, \n",
    "        ord_qty, inv_qty, sccf,\n",
    "        case when bp_tgt_cr*1.00/tot_tgt_cr is null then 0 else bp_tgt_cr*1.00/tot_tgt_cr end bp_bc, \n",
    "        case when town_tgt_cr*1.00/tot_tgt_cr is null then 0 else town_tgt_cr*1.00/tot_tgt_cr end town_bc\n",
    "    from \n",
    "        (select basepack, town, sum(ord_qty) ord_qty, sum(inv_qty) inv_qty, sum(inv_qty)*1.00/sum(ord_qty) sccf\n",
    "        from sccf_df\n",
    "        group by 1, 2\n",
    "        ) tbl0\n",
    "\n",
    "        full join\n",
    "\n",
    "        (select basepack, sum(tgt_cr) bp_tgt_cr\n",
    "        from tgt_df\n",
    "        group by 1\n",
    "        ) tbl2 using(basepack)\n",
    "\n",
    "        full join\n",
    "\n",
    "        (select town, sum(tgt_cr) town_tgt_cr\n",
    "        from tgt_df\n",
    "        group by 1\n",
    "        ) tbl3 using(town)\n",
    "\n",
    "        left join \n",
    "\n",
    "        (select distinct basepack, category\n",
    "        from tgt_df\n",
    "        ) tbl4 using(basepack), \n",
    "\n",
    "        (select sum(tgt_cr) tot_tgt_cr\n",
    "        from tgt_df\n",
    "        ) tbl5\n",
    "    order by bp_bc desc\n",
    "    '''\n",
    "    sccf_df_contrib = duckdb.query(qry).df()\n",
    "\n",
    "    # order columns\n",
    "    qry = '''\n",
    "    select \n",
    "        town, \n",
    "        max(town_bc) town_bc, \n",
    "        sum(max(town_bc)) over(order by max(town_bc) desc) town_bc_cum,\n",
    "        sum(inv_qty)*1.00/sum(ord_qty) town_sccf\n",
    "    from sccf_df_contrib\n",
    "    group by 1\n",
    "    order by town_bc desc\n",
    "    '''\n",
    "    ord_df = duckdb.query(qry).df()\n",
    "    town_ord = ord_df['town'].tolist()\n",
    "\n",
    "    # town BC\n",
    "    town_bc_cum_ord = ['town_bc_cum'] + ord_df['town_bc_cum'].tolist()\n",
    "    town_bc_cum_ord = pd.DataFrame([town_bc_cum_ord])\n",
    "    town_bc_ord = ['town_bc'] + ord_df['town_bc'].tolist()\n",
    "    town_bc_ord = pd.DataFrame([town_bc_ord])\n",
    "    town_sccf_ord = ['town_sccf'] + ord_df['town_sccf'].tolist()\n",
    "    town_sccf_ord = pd.DataFrame([town_sccf_ord])\n",
    "\n",
    "    # basepack BC\n",
    "    qry = '''\n",
    "    select \n",
    "        category, \n",
    "        basepack, \n",
    "        max(bp_bc) basepack_bc, \n",
    "        sum(max(bp_bc)) over(order by max(bp_bc) desc) basepack_bc_cum,\n",
    "        sum(inv_qty)*1.00/sum(ord_qty) basepack_sccf\n",
    "    from sccf_df_contrib\n",
    "    group by 1, 2\n",
    "    order by basepack_bc desc\n",
    "    '''\n",
    "    bp_bc_df = duckdb.query(qry).df()[['basepack_bc_cum', 'basepack_bc', 'basepack_sccf', 'category']]\n",
    "    \n",
    "    # national\n",
    "    qry = '''\n",
    "    select * \n",
    "    from \n",
    "        (select sum(inv_qty)*1.00/sum(ord_qty) national_sccf\n",
    "        from sccf_df_contrib\n",
    "        ) tbl1, \n",
    "        (select sum(inv_qty)*1.00/sum(ord_qty) national_sccf_excluding_mtsmtwt\n",
    "        from sccf_df_contrib\n",
    "        where town not in('WATER-DHAKA', 'MODERN TRADE', 'SMT & SHOPPING COMPL', 'OOH DISTRIBUTOR DHAK')\n",
    "        ) tbl2\n",
    "    '''\n",
    "    national_df = duckdb.query(qry).df()\n",
    "\n",
    "    # pivot\n",
    "    sccf_df_piv = pd.pivot_table(sccf_df_contrib.fillna(-0.01), values='sccf', index=['basepack'], columns='town', sort=False).fillna(-0.01)\n",
    "    sccf_df_piv = sccf_df_piv[town_ord]\n",
    "    \n",
    "    # path\n",
    "    path = 'C:/Users/Shithi.Maitra/OneDrive - Unilever/2d Matrices/SCCF Matrices/SCCF_2by2_Matrix_' + rec_date_from[0:7] + '.xlsx'\n",
    "\n",
    "    # if exists\n",
    "    if_exists = 1\n",
    "    try: book = load_workbook(path)\n",
    "    except: if_exists = 0\n",
    "\n",
    "    # writer\n",
    "    writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "\n",
    "    # create/retrieve/remove sheet(s)\n",
    "    if if_exists == 1: \n",
    "        writer.book = book\n",
    "        if sheet_name in book.sheetnames:\n",
    "            if rec_date_from != rec_date_to:\n",
    "                try: del writer.book[sheet_name] # sheet exists \n",
    "                except: pass                     # sheet does not exist\n",
    "            else: \n",
    "                writer.close()\n",
    "                return\n",
    "         \n",
    "    # write\n",
    "    national_df.to_excel(writer, sheet_name=sheet_name, startrow=0, startcol=3, index=False)\n",
    "    town_bc_cum_ord.to_excel(writer, sheet_name=sheet_name, startrow=2, startcol=4, header=False, index=False)\n",
    "    town_bc_ord.to_excel(writer, sheet_name=sheet_name, startrow=3, startcol=4, header=False, index=False)\n",
    "    town_sccf_ord.to_excel(writer, sheet_name=sheet_name, startrow=4, startcol=4, header=False, index=False)\n",
    "    sccf_df_piv.to_excel(writer, sheet_name=sheet_name, startrow=5, startcol=4)\n",
    "    bp_bc_df.to_excel(writer, sheet_name=sheet_name, startrow=5, startcol=0, index=False)\n",
    "\n",
    "    # adjust\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    for column_cells in worksheet.columns:\n",
    "        length = max(len(\"\".join(c for c in str(cell.value).replace(' ', 'A') if c.isalpha())) for cell in column_cells)        \n",
    "        worksheet.column_dimensions[openpyxl.utils.get_column_letter(column_cells[0].column)].width = length + 4\n",
    "    writer.close()\n",
    "    \n",
    "    # format\n",
    "    workbook = load_workbook(path)\n",
    "    worksheet = workbook[sheet_name]\n",
    "    \n",
    "    # percent\n",
    "    column_letters = [col.column_letter for col in worksheet[1]]\n",
    "    for col in column_letters: \n",
    "        for cel in worksheet[(col)]: \n",
    "            cel.number_format = \"0.00%\"\n",
    "    \n",
    "    # color\n",
    "    font = Font(bold = True, color = 'EE1111')\n",
    "    dxf = DifferentialStyle(font = font)\n",
    "    rule = Rule(type = 'cellIs', operator = 'between', formula = [0.001, national_df['national_sccf'].tolist()[0]], dxf = dxf)\n",
    "    worksheet.conditional_formatting.add('C5:GZ300', rule)\n",
    "    \n",
    "    # freeze\n",
    "    worksheet.freeze_panes = worksheet['F7']\n",
    "    \n",
    "    # save\n",
    "    workbook.save(path)\n",
    "    workbook.close()\n",
    "\n",
    "    # tabs in sheet\n",
    "    print(\"Worksheets in workbook: \")\n",
    "    print(pd.ExcelFile(path).sheet_names)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487d3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e06f96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-16', '2024-02-17', '2024-02-18']\n"
     ]
    }
   ],
   "source": [
    "# month, dates, target\n",
    "tgt_df = read_tgt_file()\n",
    "\n",
    "current_month = datetime.today().strftime('%Y-%m-%d')[0:7]\n",
    "qry = '''\n",
    "select (concat(left(current_date-2, 7), '-01')::date + generate_series::int)::text sccf_date\n",
    "from (select * from generate_series(0, 100)) tbl1 \n",
    "where generate_series < date_part('day', current_date)\n",
    "'''\n",
    "sccf_dates = duckdb.query(qry).df()['sccf_date'].tolist()\n",
    "\n",
    "# current_month = '2024-01'\n",
    "# sccf_dates = ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05', '2024-01-06', '2024-01-07', '2024-01-08', '2024-01-09', '2024-01-10', '2024-01-11', '2024-01-12', '2024-01-13', '2024-01-14', '2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18', '2024-01-19', '2024-01-20', '2024-01-21', '2024-01-22', '2024-01-23', '2024-01-24', '2024-01-25', '2024-01-26', '2024-01-27', '2024-01-28', '2024-01-29', '2024-01-30', '2024-01-31']\n",
    "\n",
    "print(sccf_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2b4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: SEC CCF % 09 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 05 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 08 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 03 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 07 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 02 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 11 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 14 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 13 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 12 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 04 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 15 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 16 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 06 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 10 Feb 2024_UBL.xlsx\n",
      "Reading: SEC CCF % 01 Feb 2024_UBL.xlsx\n"
     ]
    }
   ],
   "source": [
    "# SCCF\n",
    "rec_date_from = sccf_dates[0]\n",
    "rec_date_to = sccf_dates[len(sccf_dates)-1]\n",
    "sccf_df = fetch_read_sccf(rec_date_from, rec_date_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89576262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends', '2024-02-10']\n",
      "\n",
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends', '2024-02-10', '2024-02-11']\n",
      "\n",
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends', '2024-02-10', '2024-02-11', '2024-02-12']\n",
      "\n",
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13']\n",
      "\n",
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14']\n",
      "\n",
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15']\n",
      "\n",
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-16']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# daily\n",
    "for sccf_date in sccf_dates:\n",
    "    day_df = duckdb.query(\"select * from sccf_df where sccf_date='\" + sccf_date + \"'\").df()\n",
    "    if day_df.shape[0] == 0: continue\n",
    "    prepare_report(sccf_date, sccf_date, day_df, sccf_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb9fe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-TDP1', '2024-02-trends', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-16', '2024-02-MTD']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MTD\n",
    "prepare_report(rec_date_from, rec_date_to, sccf_df, current_month + \"-MTD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20d37466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-16', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends', '2024-02-TDP2']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # TDP-01\n",
    "# rec_date_from = current_month + \"-01\"\n",
    "# rec_date_to = current_month + \"-10\"\n",
    "# tdp_df = duckdb.query(\"select * from sccf_df where sccf_date>='\" + rec_date_from + \"' and sccf_date<='\" + rec_date_to + \"'\").df()\n",
    "# prepare_report(rec_date_from, rec_date_to, tdp_df, current_month + \"-TDP1\")\n",
    "\n",
    "# TDP-02\n",
    "rec_date_from = current_month + \"-11\"\n",
    "rec_date_to = current_month + \"-20\"\n",
    "tdp_df = duckdb.query(\"select * from sccf_df where sccf_date>='\" + rec_date_from + \"' and sccf_date<='\" + rec_date_to + \"'\").df()\n",
    "prepare_report(rec_date_from, rec_date_to, tdp_df, current_month + \"-TDP2\")\n",
    "\n",
    "# # TDP-03\n",
    "# rec_date_from = current_month + \"-21\"\n",
    "# rec_date_to = sccf_dates[len(sccf_dates)-1]\n",
    "# tdp_df = duckdb.query(\"select * from sccf_df where sccf_date>='\" + rec_date_from + \"' and sccf_date<='\" + rec_date_to + \"'\").df()\n",
    "# prepare_report(rec_date_from, rec_date_to, tdp_df, current_month + \"-TDP3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe96938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worksheets in workbook: \n",
      "['2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05', '2024-02-06', '2024-02-07', '2024-02-08', '2024-02-09', '2024-02-10', '2024-02-11', '2024-02-12', '2024-02-13', '2024-02-14', '2024-02-15', '2024-02-16', '2024-02-MTD', '2024-02-TDP1', '2024-02-trends']\n"
     ]
    }
   ],
   "source": [
    "## trend ##\n",
    "\n",
    "# path\n",
    "path = 'C:/Users/Shithi.Maitra/OneDrive - Unilever/2d Matrices/SCCF Matrices/SCCF_2by2_Matrix_' + rec_date_from[0:7] + '.xlsx'\n",
    "\n",
    "# sheets\n",
    "sheets = pd.ExcelFile(path).sheet_names\n",
    "\n",
    "# trend data\n",
    "qry = '''\n",
    "select sccf_date, basepack, town, sum(inv_qty)*1.00/sum(ord_qty) sccf\n",
    "from sccf_df\n",
    "group by 1, 2, 3\n",
    "union all\n",
    "select sccf_date, 'overall' basepack, town, sum(inv_qty)*1.00/sum(ord_qty) sccf\n",
    "from sccf_df\n",
    "group by 1, 2, 3\n",
    "union all\n",
    "select sccf_date, basepack, 'overall' town, sum(inv_qty)*1.00/sum(ord_qty) sccf\n",
    "from sccf_df\n",
    "group by 1, 2, 3\n",
    "'''\n",
    "trend_df = duckdb.query(qry).df()\n",
    "trend_df_piv = pd.pivot_table(trend_df.fillna(-0.01), values='sccf', index=['town', 'basepack'], columns='sccf_date', sort=False).fillna(-0.01)\n",
    "\n",
    "# benchmark\n",
    "qry = '''\n",
    "select sum(inv_qty)*1.00/sum(ord_qty) benchmark_sccf\n",
    "from sccf_df\n",
    "'''\n",
    "benchmark = duckdb.query(qry).df()['benchmark_sccf'].tolist()[0] \n",
    "\n",
    "# load\n",
    "book = load_workbook(path)\n",
    "\n",
    "# writer\n",
    "writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "\n",
    "# create, retrieve, remove sheets\n",
    "sheet_name = rec_date_from[0:7] + '-trends'\n",
    "writer.book = book\n",
    "if sheet_name in sheets: del writer.book[sheet_name]\n",
    "\n",
    "# write\n",
    "trend_df_piv.reset_index().to_excel(writer, sheet_name=sheet_name, startrow=0, startcol=0, index = False)\n",
    "\n",
    "# adjust\n",
    "worksheet = writer.sheets[sheet_name]\n",
    "it = 1\n",
    "for column_cells in worksheet.columns:\n",
    "    if it in [1, 2]: length = max(len(\"\".join(c for c in str(cell.value).replace(' ', 'A') if c.isalpha())) for cell in column_cells)  \n",
    "    else: length = len(str(column_cells[0].value))\n",
    "    worksheet.column_dimensions[openpyxl.utils.get_column_letter(column_cells[0].column)].width = length + 4\n",
    "    it = it + 1\n",
    "writer.close()\n",
    "\n",
    "# format\n",
    "workbook = load_workbook(path)\n",
    "worksheet = workbook[sheet_name]\n",
    "\n",
    "# freeze\n",
    "worksheet.freeze_panes = worksheet['C2']\n",
    "\n",
    "# filter\n",
    "worksheet.auto_filter.ref = worksheet.dimensions\n",
    "\n",
    "# percent\n",
    "column_letters = [col.column_letter for col in worksheet[1]]\n",
    "for col in column_letters: \n",
    "    for cel in worksheet[(col)]: \n",
    "        cel.number_format = \"0.00%\" \n",
    "        \n",
    "# color\n",
    "font = Font(bold = True, color = 'EE1111')\n",
    "dxf = DifferentialStyle(font = font)\n",
    "rule = Rule(type = 'cellIs', operator = 'between', formula = [0.001, benchmark], dxf = dxf)\n",
    "worksheet.conditional_formatting.add('C5:AH50000', rule)\n",
    "    \n",
    "# save\n",
    "workbook.save(path)\n",
    "\n",
    "# tabs in sheet\n",
    "print(\"Worksheets in workbook: \")\n",
    "print(pd.ExcelFile(path).sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b811a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to run script (mins): 34.72\n"
     ]
    }
   ],
   "source": [
    "# report\n",
    "elapsed_time = str(round((time.time() - start_time) / 60.00, 2))\n",
    "print(\"Elapsed time to run script (mins): \" + elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e952ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # analysis\n",
    "# qry = '''\n",
    "# select * \n",
    "# from \n",
    "#     (select * \n",
    "#     from \n",
    "#         (select \n",
    "#             basepack, \n",
    "#             town, \n",
    "#             sccf_date, \n",
    "#             lead(sccf_date, 1) over(partition by basepack, town order by sccf_date) sccf_date_1,\n",
    "#             lead(sccf_date, 2) over(partition by basepack, town order by sccf_date) sccf_date_2,\n",
    "#             lead(sccf_date, 3) over(partition by basepack, town order by sccf_date) sccf_date_3,\n",
    "#             lead(sccf_date, 4) over(partition by basepack, town order by sccf_date) sccf_date_4\n",
    "#         from (select basepack, town, sccf, sccf_date::date sccf_date from trend_df) tbl1\n",
    "#         where \n",
    "#             sccf<0.90\n",
    "#             and town not in('WATER-DHAKA', 'MODERN TRADE', 'SMT & SHOPPING COMPL', 'OOH DISTRIBUTOR DHAK', 'OOH DISTRIBUTOR DHAKA')\n",
    "#         ) tbl1 \n",
    "#     where \n",
    "#         sccf_date_4=(select max(sccf_date) from trend_df)\n",
    "#         and sccf_date_1-sccf_date=1\n",
    "#         and sccf_date_2-sccf_date_1=1\n",
    "#         and sccf_date_3-sccf_date_2=1\n",
    "#         and sccf_date_4-sccf_date_3=1\n",
    "#         and town='TEJGAON'\n",
    "#     ) tbl1 \n",
    "#     inner join \n",
    "#     tgt_df tbl2 using(basepack, town)\n",
    "# order by tgt_cr desc\n",
    "# limit 5\n",
    "# '''\n",
    "# df = duckdb.query(qry).df()\n",
    "\n",
    "# # send - only me grp\n",
    "# import pywhatkit\n",
    "# emo = \":unlock\\t\"\n",
    "# msg = emo + \" Are you continuously losing SCCF in UBL's very own Tejgaon? Here are packs, with < 90% SCCF for the past 5 days:\\n- \" + \"\\n- \".join(df['basepack'].tolist()) + \"\\nFind out more from this month's 2*2 SCCF matrix!\"\n",
    "# print(\"\\n\" + msg)\n",
    "# pywhatkit.sendwhatmsg_to_group_instantly(group_id=\"DXqnN42tpV27ZoVWszBH9D\", message=msg, tab_close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a3228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
