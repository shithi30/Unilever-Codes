{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa7b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "import win32com.client\n",
    "from pretty_html_table import build_table\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ed406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarweb ##\n",
    "\n",
    "def scrape_datapoint(attr_ls, val_ls, attr_ind, attr_div, attr_cls, val_div, val_cls, cat, soup_init, p):\n",
    "    \n",
    "    # accumulator\n",
    "    df_temp = pd.DataFrame()\n",
    "    \n",
    "    # attributes\n",
    "    soup = soup_init.find_all(attr_div, attrs={\"class\": attr_cls})\n",
    "    soup = eval('soup' + attr_ind)\n",
    "    for s in soup: attr_ls.append(s.get_text())\n",
    "        \n",
    "    # values\n",
    "    soup = soup_init.find_all(val_div, attrs={\"class\": val_cls})\n",
    "    for s in soup: val_ls.append(s.get_text())\n",
    "        \n",
    "    # store\n",
    "    df_temp['value'] = val_ls\n",
    "    df_temp['attribute'] = attr_ls\n",
    "    df_temp['category'] = cat\n",
    "    df_temp['platform'] = p\n",
    "    \n",
    "    # return\n",
    "    return df_temp\n",
    "\n",
    "def scrape_similarweb(platforms):\n",
    "\n",
    "    # accumulators\n",
    "    start_time = time.time()\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # preference\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('ignore-certificate-errors')\n",
    "\n",
    "    # open window\n",
    "    for p in platforms:\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.maximize_window()\n",
    "        \n",
    "        # url\n",
    "        url = 'https://www.similarweb.com/website/' + p + '/'\n",
    "        driver.get(url)\n",
    "\n",
    "        # load\n",
    "        time.sleep(10)\n",
    "\n",
    "        # scroll\n",
    "        SCROLL_PAUSE_TIME = 3\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height: break\n",
    "            last_height = new_height\n",
    "\n",
    "        # soup\n",
    "        soup_init = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # close window\n",
    "        driver.close()\n",
    "\n",
    "        # marketing channels        \n",
    "        df = df._append(scrape_datapoint([], [], \"[:]\", \"span\", \"wa-traffic-source-label__title\", \"tspan\", \"wa-traffic-sources__channels-data-label\", 'marketing channel', soup_init, p))\n",
    "        # age\n",
    "        df = df._append(scrape_datapoint([], [], \"[2]\", \"g\", \"highcharts-axis-labels highcharts-xaxis-labels\", \"tspan\", \"wa-demographics__age-data-label\", 'age', soup_init, p))\n",
    "        # intro\n",
    "        df = df._append(scrape_datapoint([], [], \"[:]\", \"dt\", \"app-company-info__list-item app-company-info__list-item--title\", \"dd\", \"app-company-info__list-item app-company-info__list-item--value\", 'intro', soup_init, p))\n",
    "        # ranks\n",
    "        df = df._append(scrape_datapoint([], [], \"[:]\", \"p\", \"wa-rank-list__title\", \"p\", \"wa-rank-list__value\", 'rank', soup_init, p))\n",
    "        # gender\n",
    "        df = df._append(scrape_datapoint([], [], \"[:]\", \"span\", \"wa-demographics__gender-legend-item-title\", \"span\", \"wa-demographics__gender-legend-item-value\", 'gender', soup_init, p))\n",
    "        # last 3 months' visit\n",
    "        # df = df._append(scrape_datapoint(['Month - 3', 'Month - 2', 'Month - 1'], [], \"[:]\", \"\", \"\", \"tspan\", \"wa-traffic__chart-data-label\", 'visits last 3 months', soup_init, p))\n",
    "        # last month traffic\n",
    "        df = df._append(scrape_datapoint([], [], \"[:]\", \"p\", \"engagement-list__item-name\", \"p\", \"engagement-list__item-value\", 'last month', soup_init, p))\n",
    "        # report\n",
    "        print(\"Statistics scraped for: \" + p)\n",
    "        \n",
    "    # cleaning\n",
    "    qry = '''\n",
    "    select distinct\n",
    "        platform,\n",
    "        category,\n",
    "        attribute,\n",
    "        value,\n",
    "        case \n",
    "            when value like '%-%' then null\n",
    "            when value like '#%' then replace(right(value, length(value)-1), ',', '')::float\n",
    "            when right(value, 1)='%' then left(value, length(value)-1)::float/100\n",
    "            when right(value, 1)='M' then left(value, length(value)-1)::float*1000000\n",
    "            when right(value, 1)='K' then left(value, length(value)-1)::float*1000\n",
    "            when value like '%:%' then \n",
    "                (string_split(value, ':')[1]::int*3600\n",
    "                +string_split(value, ':')[2]::int*60\n",
    "                +string_split(value, ':')[3]::int)::float\n",
    "            when value~'^[0-9\\.]+$' then value::float\n",
    "            else null\n",
    "        end value_cleaned,\n",
    "        current_date::text report_date\n",
    "    from df\n",
    "    '''\n",
    "    df = duckdb.query(qry).df().fillna('')\n",
    "    \n",
    "    # csv\n",
    "    folder = r'C:\\\\Users\\\\shith\\\\Unilever Takeaway\\\\Unilever Codes\\\\Scraping Scripts\\\\'\n",
    "    filename = folder + \"similarweb_ecom_compare_data.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    # analysis\n",
    "    qry = '''\n",
    "    select \n",
    "        platform,\n",
    "        max(case when attribute='Total Visits' then value else null end) \"visits last month\",\n",
    "        max(case when attribute='Avg Visit Duration' then value else null end) \"avg. visit duration\",\n",
    "        max(case when attribute='Pages per Visit' then value else null end) \"pages/visit\",\n",
    "        max(case when attribute='Female' then value else null end) \"female visitors pct\",\n",
    "        max(case when attribute='25 - 34' then value else null end) \"age 25 - 34 visitors pct\",\n",
    "        max(case when attribute='Category Rank' then value else null end) \"category rank\",\n",
    "        max(case when attribute='Organic Search' then value else null end) \"organic search marketing pct\",\n",
    "        max(report_date) \"report date\"\n",
    "    from df\n",
    "    group by 1\n",
    "    '''\n",
    "    res_df = duckdb.query(qry).df().fillna('')\n",
    "    \n",
    "    # update\n",
    "    put_to_sheet(df, res_df)\n",
    "    \n",
    "    # stats\n",
    "    print(\"\\nTotal datapoints found: \" + str(df.shape[0]))\n",
    "    elapsed_time = str(round((time.time() - start_time) / 60.00, 2))\n",
    "    print(\"Elapsed time to run script (mins): \" + elapsed_time)\n",
    "        \n",
    "    # return\n",
    "    return res_df\n",
    "\n",
    "def put_to_sheet(data_df, summary_df):\n",
    "    \n",
    "    # credentials\n",
    "    SERVICE_ACCOUNT_FILE = 'read-write-to-gsheet-apis-1-04f16c652b1e.json'\n",
    "    SAMPLE_SPREADSHEET_ID = '1gkLRp59RyRw4UFds0-nNQhhWOaS4VFxtJ_Hgwg2x2A0'\n",
    "    SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "    # APIs\n",
    "    creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    sheet = service.spreadsheets()\n",
    "\n",
    "    # extract\n",
    "    values = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID, range='SimilarWeb!A1:F').execute().get('values', [])\n",
    "    df_prev = pd.DataFrame(values[1:] , columns = values[0])\n",
    "    values = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID, range='SimilarWeb!H1:P').execute().get('values', [])\n",
    "    df_sum_prev = pd.DataFrame(values[1:] , columns = values[0])\n",
    "    \n",
    "    # transform\n",
    "    df_now = duckdb.query('''select * from (select * from df_prev where left(report_date::text, 7)!=left(current_date::text, 7) union all select * from data_df) tbl1 order by report_date desc, platform asc, category asc, attribute asc''').df().fillna('')\n",
    "    df_sum_now = duckdb.query('''select * from (select * from df_sum_prev where left(\"report date\", 7)!=left(current_date::text, 7) union all select * from summary_df) tbl1 order by \"report date\" desc, platform asc''').df().fillna('')\n",
    "    \n",
    "    # load\n",
    "    res = sheet.values().clear(spreadsheetId=SAMPLE_SPREADSHEET_ID, range='SimilarWeb').execute()\n",
    "    res = sheet.values().update(spreadsheetId=SAMPLE_SPREADSHEET_ID, range=\"'SimilarWeb'!A1\", valueInputOption='USER_ENTERED', body={'values': [df_now.columns.values.tolist()] + df_now.values.tolist()}).execute()\n",
    "    res = sheet.values().update(spreadsheetId=SAMPLE_SPREADSHEET_ID, range=\"'SimilarWeb'!H1\", valueInputOption='USER_ENTERED', body={'values': [df_sum_now.columns.values.tolist()] + df_sum_now.values.tolist()}).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f566f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics scraped for: ushopbd.com\n",
      "Statistics scraped for: chaldal.com\n",
      "Statistics scraped for: shwapno.com\n",
      "Statistics scraped for: daraz.com.bd\n",
      "Statistics scraped for: foodpanda.com.bd\n",
      "Statistics scraped for: shajgoj.com\n",
      "Statistics scraped for: ohsogo.com\n",
      "\n",
      "Total datapoints found: 203\n",
      "Elapsed time to run script (mins): 2.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>visits last month</th>\n",
       "      <th>avg. visit duration</th>\n",
       "      <th>pages/visit</th>\n",
       "      <th>female visitors pct</th>\n",
       "      <th>age 25 - 34 visitors pct</th>\n",
       "      <th>category rank</th>\n",
       "      <th>organic search marketing pct</th>\n",
       "      <th>report date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shajgoj.com</td>\n",
       "      <td>3.1M</td>\n",
       "      <td>00:01:35</td>\n",
       "      <td>2.63</td>\n",
       "      <td>35.24%</td>\n",
       "      <td>36.29%</td>\n",
       "      <td>#2,187</td>\n",
       "      <td>70.19%</td>\n",
       "      <td>2024-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ohsogo.com</td>\n",
       "      <td>501K</td>\n",
       "      <td>00:03:32</td>\n",
       "      <td>4.96</td>\n",
       "      <td>45.04%</td>\n",
       "      <td>35.22%</td>\n",
       "      <td>#740</td>\n",
       "      <td>28.95%</td>\n",
       "      <td>2024-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ushopbd.com</td>\n",
       "      <td>219.7K</td>\n",
       "      <td>00:02:47</td>\n",
       "      <td>3.59</td>\n",
       "      <td>20.02%</td>\n",
       "      <td>29.74%</td>\n",
       "      <td>#6,717</td>\n",
       "      <td>27.61%</td>\n",
       "      <td>2024-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shwapno.com</td>\n",
       "      <td>248.9K</td>\n",
       "      <td>00:03:51</td>\n",
       "      <td>5.39</td>\n",
       "      <td>21.1%</td>\n",
       "      <td>35.81%</td>\n",
       "      <td>#2,527</td>\n",
       "      <td>64.96%</td>\n",
       "      <td>2024-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daraz.com.bd</td>\n",
       "      <td>10.9M</td>\n",
       "      <td>00:05:18</td>\n",
       "      <td>6.90</td>\n",
       "      <td>22.44%</td>\n",
       "      <td>35.82%</td>\n",
       "      <td>#101</td>\n",
       "      <td>35.03%</td>\n",
       "      <td>2024-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>foodpanda.com.bd</td>\n",
       "      <td>910.3K</td>\n",
       "      <td>00:05:28</td>\n",
       "      <td>7.30</td>\n",
       "      <td>27.43%</td>\n",
       "      <td>37.04%</td>\n",
       "      <td>#1,565</td>\n",
       "      <td>22.87%</td>\n",
       "      <td>2024-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chaldal.com</td>\n",
       "      <td>2.1M</td>\n",
       "      <td>00:02:50</td>\n",
       "      <td>4.12</td>\n",
       "      <td>23.5%</td>\n",
       "      <td>37.95%</td>\n",
       "      <td>#937</td>\n",
       "      <td>47.98%</td>\n",
       "      <td>2024-04-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           platform visits last month avg. visit duration pages/visit  \\\n",
       "0       shajgoj.com              3.1M            00:01:35        2.63   \n",
       "1        ohsogo.com              501K            00:03:32        4.96   \n",
       "2       ushopbd.com            219.7K            00:02:47        3.59   \n",
       "3       shwapno.com            248.9K            00:03:51        5.39   \n",
       "4      daraz.com.bd             10.9M            00:05:18        6.90   \n",
       "5  foodpanda.com.bd            910.3K            00:05:28        7.30   \n",
       "6       chaldal.com              2.1M            00:02:50        4.12   \n",
       "\n",
       "  female visitors pct age 25 - 34 visitors pct category rank  \\\n",
       "0              35.24%                   36.29%        #2,187   \n",
       "1              45.04%                   35.22%          #740   \n",
       "2              20.02%                   29.74%        #6,717   \n",
       "3               21.1%                   35.81%        #2,527   \n",
       "4              22.44%                   35.82%          #101   \n",
       "5              27.43%                   37.04%        #1,565   \n",
       "6               23.5%                   37.95%          #937   \n",
       "\n",
       "  organic search marketing pct report date  \n",
       "0                       70.19%  2024-04-25  \n",
       "1                       28.95%  2024-04-25  \n",
       "2                       27.61%  2024-04-25  \n",
       "3                       64.96%  2024-04-25  \n",
       "4                       35.03%  2024-04-25  \n",
       "5                       22.87%  2024-04-25  \n",
       "6                       47.98%  2024-04-25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = scrape_similarweb(['ushopbd.com', 'chaldal.com', 'shwapno.com', 'daraz.com.bd', 'foodpanda.com.bd', 'shajgoj.com', 'ohsogo.com'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1964810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# email\n",
    "ol = win32com.client.Dispatch(\"outlook.application\")\n",
    "olmailitem = 0x0\n",
    "newmail = ol.CreateItem(olmailitem)\n",
    "\n",
    "# subject, recipients\n",
    "newmail.Subject = 'Similarweb Comparisons ' + time.strftime('%d-%b-%y')\n",
    "newmail.To = \"avra.barua@unilever.com; safa-e.nafee@unilever.com; rafid-al.mahmood@unilever.com; zoya.rashid@unilever.com; samsuddoha.nayeem@unilever.com\"\n",
    "newmail.BCC = \"shithi30@outlook.com\"\n",
    "\n",
    "# body\n",
    "newmail.HTMLbody = f'''\n",
    "Dear concern,<br><br>\n",
    "It may be important to analyze e-com platforms' comparative performance in order to maximize ROI. Hence, traffic and engagement data have been fetched from <a href=\"www.similarweb.com\">similarweb.com</a>.\n",
    "''' + build_table(df, 'green_light') + '''\n",
    "Note that, the statistics presented are reflections of the mentioned website at the time of scraping. More parameters are available in the attachment. This is an auto email via <i>win32com</i>.<br><br>\n",
    "Thanks,<br>\n",
    "Shithi Maitra<br>\n",
    "Asst. Manager, Cust. Service Excellence<br>\n",
    "Unilever BD Ltd.<br>\n",
    "'''\n",
    "\n",
    "# attachment(s) \n",
    "folder = r'C:\\\\Users\\\\shith\\\\Unilever Takeaway\\\\Unilever Codes\\\\Scraping Scripts\\\\'\n",
    "filename = folder + \"similarweb_ecom_compare_data.csv\"\n",
    "newmail.Attachments.Add(filename)\n",
    "\n",
    "# display\n",
    "newmail.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e48f5-148e-499e-ba62-20972a018ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
